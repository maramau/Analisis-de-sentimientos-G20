{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13/06/2021: Actualice el codigo, agregue unos diccionarios y cambie el nombre de las variables. Pero no lo he probado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Dado el camino de un archivo, devuelvo su contenido como un DataFrame de Pandas, donde cada texto es un tweet sin procesar\n",
    "def abrirArchivo(filepath):\n",
    "    df = pd.read_csv(filepath, sep='\\t', encoding='utf-8').dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dado un DataFrame y score minimo\n",
    "#Devuelvo un dataframe que contiene solo las filas con scores mayores al minimo\n",
    "def remove_low_score_rows(df_tweets, min_score):\n",
    "    df_tweets = df_tweets[df_tweets._score>min_score]\n",
    "    df_tweets = df_tweets.drop(columns=['_score'])\n",
    "    return df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defino funciones para eliminar los elementos innecesarios de los textos\n",
    "import regex as re\n",
    "\n",
    "#Dado un DataFrame con una lista de frases, filtro sus hashtags\n",
    "def remove_hashtags(df_sentences):\n",
    "    for i in range(len(df_sentences)):\n",
    "        df_sentences.loc[i, ('text')] = re.sub(r'#(\\s)?(\\w)+|(#)', '', df_sentences.loc[i, ('text')])\n",
    "\n",
    "#Dado un DataFrame con una lista de frases, filtro \n",
    " #el RT @Usuario al inicio del campo texto de los retweets y los @Usuario en cualquier parte del texto\n",
    "def remove_rt(df_sentences):\n",
    "    for i in range(len(df_sentences)):\n",
    "        df_sentences.loc[i, ('text')] = re.sub(r'(rt @\\w+(:\\s)?)|(@\\w+)|(@)|(RT @\\w+(:\\s)?)', '', df_sentences.loc[i, ('text')])\n",
    "\n",
    "#Dado un DataFrame con una lista de frases, filtro las URLs\n",
    "def remove_url(df_sentences):\n",
    "    for i in range(len(df_sentences)):\n",
    "        df_sentences.loc[i, ('text')] = re.sub(r'(http(s)?://.*)+', '', df_sentences.loc[i, ('text')])\n",
    "\n",
    "#Dado un DataFrame con una lista de frases, filtro los signos de puntuacion\n",
    "def remove_punctuation(df_sentences):\n",
    "    for i in range(len(df_sentences)):\n",
    "        df_sentences.loc[i, ('text')] = re.sub(r'[\\\\\\.,;:!¡?¿\\-_\\“\\”\\\"\\‘\\’\\'\\s$\\)\\(\\%]|(\\'s)', ' ', df_sentences.loc[i, ('text')])\n",
    "        df_sentences.loc[i, ('text')] = re.sub(r'(\\s*\\n\\s*)+|(\\s)+', ' ', df_sentences.loc[i, ('text')])\n",
    "\n",
    "#Dado un DataFrame con una lista de frases, llamo a todos los filtros definidos anteriormente \n",
    "def remove_all(df_sentences):\n",
    "    remove_rt(df_sentences)\n",
    "    remove_hashtags(df_sentences)\n",
    "    remove_url(df_sentences)\n",
    "    remove_punctuation(df_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quito las stopwords\n",
    "import spacy\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#Dado un DataFrame con una lista de frases, filtro las stopwords\n",
    "def remove_stopwords(df_sentences, spacy_model):\n",
    "    #stop_words = set(stopwords.words(lang))\n",
    "    stop_words = spacy.load(spacy_model).Defaults.stop_words\n",
    "    stop_words.add('amp')\n",
    "    filtered_words = []\n",
    "    \n",
    "    for i in range(len(df_sentences)):\n",
    "        words_wo_stop_words = list()\n",
    "        words = df_sentences.loc[i, ('text')].split()\n",
    "        for word in words:\n",
    "            if(word.lower() not in stop_words) and (len(word) > 1):\n",
    "                words_wo_stop_words.append(word)\n",
    "        df_sentences.loc[i, ('text')] = ' '.join(words_wo_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import lemminflect\n",
    "\n",
    "#Dado un DataFrame con una lista de frases y un modelo de spacy, paso palabras a sus lemmas\n",
    "def transform_lemmas(df_sentences, spacy_model):\n",
    "    nlp = spacy.load(spacy_model)\n",
    "\n",
    "    for i in range(len(df_sentences)):\n",
    "        words_lemmas = list()\n",
    "        words_nlp = nlp(df_sentences.loc[i, ('text')])\n",
    "        for word in words_nlp:\n",
    "            words_lemmas.append(word._.lemma())\n",
    "        df_sentences.loc[i, ('text')] = ' '.join(words_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dado un DataFrame con una lista de frases, remuevo las frases vacias\n",
    "def remove_empty(df_tweets):\n",
    "    df_tweets = df_tweets.replace(r'( )+',' ', regex=True)\n",
    "    df_tweets = df_tweets.replace(r'(\\n)+','\\n', regex=True)\n",
    "    df_tweets = df_tweets.dropna(how='all')\n",
    "    \n",
    "    return df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dado un DataFrame con una lista de frases, remuevo las frases duplicadas\n",
    "def remove_duplicates(df_tweets):\n",
    "    return df_tweets.drop_duplicates(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recibo una lista de frases y datos sobre su procedencia y las escribo en un archivo\n",
    "def escribirArchivoTweetsProc(df_tweets, name_file, year, lang):\n",
    "    path_proc = 'results_processed/'\n",
    "    filepath = path_proc + str(year) + '/' + str(lang)+ '/' + name_file\n",
    "    df_tweets.to_csv(filepath, encoding='utf-8', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEMP\n",
    "def escribirArchivoToLabelProc(df_tweets, name_file, lang):\n",
    "    path_proc = 'toLabel//proc'\n",
    "    filepath = path_proc + '//' + str(lang)+ '//' + name_file\n",
    "    df_tweets.to_csv(filepath, encoding='utf-8', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatizo el proceso de abrir los archivos y procesarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_temas = 4\n",
    "years = [2018,2020,2021]\n",
    "years = [2021]\n",
    "langs = ['pt','es','en']\n",
    "min_score = 0\n",
    "path_results = 'results/'\n",
    "dic_languages = {'en': 'english', 'es': 'spanish', 'pt': 'portuguese'}\n",
    "dic_spacy_models = {'en': 'en_core_web_lg', 'es': 'es_core_news_lg', 'pt': 'pt_core_news_lg'}\n",
    "\n",
    "#Separo los paises segun el lenguaje de sus tweets\n",
    "dic_countries = {'en': ['alemania', 'arabia', 'australia', 'brasil', 'canada', 'china', 'corea del sur', 'francia', \n",
    "                        'india', 'indonesia', 'italia', 'japon', 'uk', 'rusia', 'sudafrica', 'turquia', 'eu', 'usa'],\n",
    "                'es': ['argentina', 'mexico'],\n",
    "                'pt':['brasil']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: 2021 lang: pt country: brasil subject: 0\n",
      "year: 2021 lang: pt country: brasil subject: 1\n",
      "year: 2021 lang: pt country: brasil subject: 2\n",
      "year: 2021 lang: pt country: brasil subject: 3\n",
      "year: 2021 lang: es country: argentina subject: 0\n",
      "year: 2021 lang: es country: argentina subject: 1\n",
      "year: 2021 lang: es country: argentina subject: 2\n",
      "year: 2021 lang: es country: argentina subject: 3\n",
      "year: 2021 lang: es country: mexico subject: 0\n",
      "year: 2021 lang: es country: mexico subject: 1\n",
      "year: 2021 lang: es country: mexico subject: 2\n",
      "year: 2021 lang: es country: mexico subject: 3\n",
      "year: 2021 lang: en country: alemania subject: 0\n",
      "year: 2021 lang: en country: alemania subject: 1\n",
      "year: 2021 lang: en country: alemania subject: 2\n",
      "year: 2021 lang: en country: alemania subject: 3\n",
      "year: 2021 lang: en country: arabia subject: 0\n",
      "year: 2021 lang: en country: arabia subject: 1\n",
      "year: 2021 lang: en country: arabia subject: 2\n",
      "year: 2021 lang: en country: arabia subject: 3\n",
      "year: 2021 lang: en country: australia subject: 0\n",
      "year: 2021 lang: en country: australia subject: 1\n",
      "year: 2021 lang: en country: australia subject: 2\n",
      "year: 2021 lang: en country: australia subject: 3\n",
      "year: 2021 lang: en country: brasil subject: 0\n",
      "year: 2021 lang: en country: brasil subject: 1\n",
      "year: 2021 lang: en country: brasil subject: 2\n",
      "year: 2021 lang: en country: brasil subject: 3\n",
      "year: 2021 lang: en country: canada subject: 0\n",
      "year: 2021 lang: en country: canada subject: 1\n",
      "year: 2021 lang: en country: canada subject: 2\n",
      "year: 2021 lang: en country: canada subject: 3\n",
      "year: 2021 lang: en country: china subject: 0\n",
      "year: 2021 lang: en country: china subject: 1\n",
      "year: 2021 lang: en country: china subject: 2\n",
      "year: 2021 lang: en country: china subject: 3\n",
      "year: 2021 lang: en country: corea del sur subject: 0\n",
      "year: 2021 lang: en country: corea del sur subject: 1\n",
      "year: 2021 lang: en country: corea del sur subject: 2\n",
      "year: 2021 lang: en country: corea del sur subject: 3\n",
      "year: 2021 lang: en country: francia subject: 0\n",
      "year: 2021 lang: en country: francia subject: 1\n",
      "year: 2021 lang: en country: francia subject: 2\n",
      "year: 2021 lang: en country: francia subject: 3\n",
      "year: 2021 lang: en country: india subject: 0\n",
      "year: 2021 lang: en country: india subject: 1\n",
      "year: 2021 lang: en country: india subject: 2\n",
      "year: 2021 lang: en country: india subject: 3\n",
      "year: 2021 lang: en country: indonesia subject: 0\n",
      "year: 2021 lang: en country: indonesia subject: 1\n",
      "year: 2021 lang: en country: indonesia subject: 2\n",
      "year: 2021 lang: en country: indonesia subject: 3\n",
      "year: 2021 lang: en country: italia subject: 0\n",
      "year: 2021 lang: en country: italia subject: 1\n",
      "year: 2021 lang: en country: italia subject: 2\n",
      "year: 2021 lang: en country: italia subject: 3\n",
      "year: 2021 lang: en country: japon subject: 0\n",
      "year: 2021 lang: en country: japon subject: 1\n",
      "year: 2021 lang: en country: japon subject: 2\n",
      "year: 2021 lang: en country: japon subject: 3\n",
      "year: 2021 lang: en country: uk subject: 0\n",
      "year: 2021 lang: en country: uk subject: 1\n",
      "year: 2021 lang: en country: uk subject: 2\n",
      "year: 2021 lang: en country: uk subject: 3\n",
      "year: 2021 lang: en country: rusia subject: 0\n",
      "year: 2021 lang: en country: rusia subject: 1\n",
      "year: 2021 lang: en country: rusia subject: 2\n",
      "year: 2021 lang: en country: rusia subject: 3\n",
      "year: 2021 lang: en country: sudafrica subject: 0\n",
      "year: 2021 lang: en country: sudafrica subject: 1\n",
      "year: 2021 lang: en country: sudafrica subject: 2\n",
      "year: 2021 lang: en country: sudafrica subject: 3\n",
      "year: 2021 lang: en country: turquia subject: 0\n",
      "year: 2021 lang: en country: turquia subject: 1\n",
      "year: 2021 lang: en country: turquia subject: 2\n",
      "year: 2021 lang: en country: turquia subject: 3\n",
      "year: 2021 lang: en country: eu subject: 0\n",
      "year: 2021 lang: en country: eu subject: 1\n",
      "year: 2021 lang: en country: eu subject: 2\n",
      "year: 2021 lang: en country: eu subject: 3\n",
      "year: 2021 lang: en country: usa subject: 0\n",
      "year: 2021 lang: en country: usa subject: 1\n",
      "year: 2021 lang: en country: usa subject: 2\n",
      "year: 2021 lang: en country: usa subject: 3\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"d14624d5-625c-456a-8b86-4317303a94f9\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"d14624d5-625c-456a-8b86-4317303a94f9\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify\n",
    "\n",
    "for year_g20 in years:\n",
    "    for lang in langs:\n",
    "        list_countries = dic_countries[lang]\n",
    "        lang_stopwords = dic_languages[lang]\n",
    "        spacy_model = dic_spacy_models[lang]\n",
    "        for country in list_countries:\n",
    "            for subject in range(cant_temas):\n",
    "                print('year: '+str(year_g20)+' lang: '+str(lang)+' country: '+str(country)+' subject: '+str(subject))\n",
    "                name_file = country + ' ' + str(year_g20) + ' - Tema ' + str(subject) + '.csv'\n",
    "                filepath = path_results + str(year_g20) + '/' + lang + '/' + name_file\n",
    "                df_tweets = abrirArchivo(filepath)\n",
    "                df_tweets = remove_low_score_rows(df_tweets, min_score)\n",
    "                remove_all(df_tweets)\n",
    "                remove_stopwords(df_tweets, spacy_model)\n",
    "                transform_lemmas(df_tweets, spacy_model)\n",
    "                df_tweets = remove_empty(df_tweets)\n",
    "                df_tweets = remove_duplicates(df_tweets)\n",
    "                escribirArchivoTweetsProc(df_tweets, name_file, year_g20, lang)\n",
    "                \n",
    "%notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"510025c4-93c8-4602-bd64-d6a4faddfda0\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"510025c4-93c8-4602-bd64-d6a4faddfda0\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TEMP\n",
    "%load_ext jupyternotify\n",
    "\n",
    "path = 'toLabel\\\\'\n",
    "names = ['Ana', 'Axel', 'Fernando', 'Mauro']\n",
    "langs = ['es','en']\n",
    "\n",
    "for name in names:\n",
    "    for lang in langs:\n",
    "        lang_stopwords = dic_languages[lang]\n",
    "        spacy_model = dic_spacy_models[lang]\n",
    "        name_file = 'toLabel-other-' + name + '-' + lang +'.csv'\n",
    "        filepath = path + lang + '\\\\' + name_file\n",
    "        df_tweets = abrirArchivo(filepath)\n",
    "        #df_tweets = remove_low_score_rows(df_tweets, min_score)\n",
    "        remove_all(df_tweets)\n",
    "        remove_stopwords(df_tweets, spacy_model)\n",
    "        transform_lemmas(df_tweets, spacy_model)\n",
    "        df_tweets = remove_empty(df_tweets)\n",
    "        df_tweets = remove_duplicates(df_tweets)\n",
    "        escribirArchivoToLabelProc(df_tweets, name_file, lang)\n",
    "                \n",
    "%notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"602e3e26-5fed-4f0e-bc2b-0764d9b9a547\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"602e3e26-5fed-4f0e-bc2b-0764d9b9a547\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TEMP\n",
    "%load_ext jupyternotify\n",
    "\n",
    "path = 'toLabel\\\\'\n",
    "langs = ['es','en']\n",
    "\n",
    "for lang in langs:\n",
    "    lang_stopwords = dic_languages[lang]\n",
    "    spacy_model = dic_spacy_models[lang]\n",
    "    name_file = 'toLabel-common-' + lang +'.csv'\n",
    "    filepath = path + lang + '\\\\' + name_file\n",
    "    df_tweets = abrirArchivo(filepath)\n",
    "    remove_all(df_tweets)\n",
    "    remove_stopwords(df_tweets, spacy_model)\n",
    "    transform_lemmas(df_tweets, spacy_model)\n",
    "    df_tweets = remove_empty(df_tweets)\n",
    "    df_tweets = remove_duplicates(df_tweets)\n",
    "    escribirArchivoToLabelProc(df_tweets, name_file, lang)\n",
    "    \n",
    "%notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
