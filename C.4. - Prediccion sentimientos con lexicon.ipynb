{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbda7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e8c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dado un lenguaje\n",
    "    # Devuelvo un diccionario con pares clave-valor donde\n",
    "    # La clave es una palabra en el lenguaje elegido\n",
    "    # El valor es una lista de 0's y 1's, donde cada 1 indica que un sentimiento es sentido\n",
    "def openLexicon(lang):\n",
    "    if (lang == 'es'):\n",
    "        dropLang = 'en'\n",
    "    else:\n",
    "        dropLang = 'es'\n",
    "    df = pd.read_csv('datasets/lexicon/nrc_emotion_lexicon.csv', delimiter=',',encoding='UTF-8').dropna()\n",
    "    df.drop([dropLang, 'Positive', 'Negative'], axis=1, inplace=True)\n",
    "    df.rename(columns = {lang:'word'}, inplace = True)\n",
    "    \n",
    "    dic = df.set_index('word').T.to_dict('list')\n",
    "    \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afd34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dado un filename, abro un archivo de la carpeta proc y devuelvo un Pandas dataframe\n",
    "def readFile(year, lang, filename):\n",
    "    path_proc = 'results_processed/'+str(year)+'/'+lang+'/'\n",
    "    df = pd.read_csv(path_proc+filename +'.csv', sep='\\t', encoding='utf-8')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10770fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados un dataframe con fechas y textos y un obj que representa un lexicon\n",
    "# Devuelvo un json, el cual tiene como claves las fechas created_at y los valores son una lista de apariciones de sentimientos en ese dia\n",
    "def predictDaily(df, lexicon):\n",
    "    json = {}\n",
    "    df['text'] = df['text'].values.astype('U')\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'], format='%a %b %d %H:%M:%S %z %Y')\n",
    "    df.sort_values(by='created_at',ascending=True, inplace=True)\n",
    "    df.reset_index().drop('index', axis=1)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        date = df['created_at'][i].date()\n",
    "        text = df.iloc[i]['text']\n",
    "        if (json.get(date) == None):\n",
    "            json[date] = [0,0,0,0,0,0,0,0,0]\n",
    "            \n",
    "        temp = [0,0,0,0,0,0,0,0,0]\n",
    "        words = text.split(\" \")\n",
    "        for word in words:\n",
    "            l = lexicon.get(word.lower())\n",
    "            if (l != None):\n",
    "                # Add all emotions from word \n",
    "                for i in range(len(l)):\n",
    "                    temp[i] += l[i]\n",
    "        #print(str(date) + str(temp))\n",
    "        # Veo cual es el sentimiento mas sentido\n",
    "        maxVotes = 0\n",
    "        for cant in temp:\n",
    "            if (cant > maxVotes):\n",
    "                maxVotes = cant\n",
    "\n",
    "        # Add the most voted emotions\n",
    "        if(maxVotes == 0):\n",
    "            json[date][8] += 1\n",
    "        else:\n",
    "            for i in range(len(temp)):\n",
    "                if (temp[i] == maxVotes):\n",
    "                    json[date][i] += 1\n",
    "    \n",
    "    return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec4aa7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPFUL\n",
    "#date = \"/\".join(df[\"created_at\"][j].split(\"-\"))\n",
    "#rows[date] = {\"date\":'', \"t\":str(j), \"No emo\":0, \"Joy\":0, \"Anger\":0, \"Sadness\":0,\n",
    "#               \"Disgust\":0, \"Fear\":0, \"Trust\":0, \"Surprise\":0, \"Anticipation\":0,\n",
    "#               \"topic0\":0, \"topic1\":0, \"topic2\":0, \"topic3\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc458b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separo los paises segun el lenguaje de sus tweets\n",
    "dic_countries = {'en': ['alemania', 'arabia', 'australia', 'brasil', 'canada', 'china', 'corea del sur', 'francia', \n",
    "                        'india', 'indonesia', 'italia', 'japon', 'uk', 'rusia', 'sudafrica', 'turquia', 'eu', 'usa'],\n",
    "                'es': ['argentina', 'mexico']}\n",
    "\n",
    "years = [2018, 2020, 2021]\n",
    "langs = ['es','en']\n",
    "model = 'lexicon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef6ae57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-09962c71b637>:14: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  dic = df.set_index('word').T.to_dict('list')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 argentina 0\n",
      "2018 argentina 1\n",
      "2018 argentina 2\n",
      "2018 argentina 3\n",
      "2018 mexico 0\n",
      "2018 mexico 1\n",
      "2018 mexico 2\n",
      "2018 mexico 3\n",
      "2018 alemania 0\n",
      "2018 alemania 1\n",
      "2018 alemania 2\n",
      "2018 alemania 3\n",
      "2018 arabia 0\n",
      "2018 arabia 1\n",
      "2018 arabia 2\n",
      "2018 arabia 3\n",
      "2018 australia 0\n",
      "2018 australia 1\n",
      "2018 australia 2\n",
      "2018 australia 3\n",
      "2018 brasil 0\n",
      "2018 brasil 1\n",
      "2018 brasil 2\n",
      "2018 brasil 3\n",
      "2018 canada 0\n",
      "2018 canada 1\n",
      "2018 canada 2\n",
      "2018 canada 3\n",
      "2018 china 0\n",
      "2018 china 1\n",
      "2018 china 2\n",
      "2018 china 3\n",
      "2018 corea del sur 0\n",
      "2018 corea del sur 1\n",
      "2018 corea del sur 2\n",
      "2018 corea del sur 3\n",
      "2018 francia 0\n",
      "2018 francia 1\n",
      "2018 francia 2\n",
      "2018 francia 3\n",
      "2018 india 0\n",
      "2018 india 1\n",
      "2018 india 2\n",
      "2018 india 3\n",
      "2018 indonesia 0\n",
      "2018 indonesia 1\n",
      "2018 indonesia 2\n",
      "2018 indonesia 3\n",
      "2018 italia 0\n",
      "2018 italia 1\n",
      "2018 italia 2\n",
      "2018 italia 3\n",
      "2018 japon 0\n",
      "2018 japon 1\n",
      "2018 japon 2\n",
      "2018 japon 3\n",
      "2018 uk 0\n",
      "2018 uk 1\n",
      "2018 uk 2\n",
      "2018 uk 3\n",
      "2018 rusia 0\n",
      "2018 rusia 1\n",
      "2018 rusia 2\n",
      "2018 rusia 3\n",
      "2018 sudafrica 0\n",
      "2018 sudafrica 1\n",
      "2018 sudafrica 2\n",
      "2018 sudafrica 3\n",
      "2018 turquia 0\n",
      "2018 turquia 1\n",
      "2018 turquia 2\n",
      "2018 turquia 3\n",
      "2018 eu 0\n",
      "2018 eu 1\n",
      "2018 eu 2\n",
      "2018 eu 3\n",
      "2018 usa 0\n",
      "2018 usa 1\n",
      "2018 usa 2\n",
      "2018 usa 3\n",
      "2020 argentina 0\n",
      "2020 argentina 1\n",
      "2020 argentina 2\n",
      "2020 argentina 3\n",
      "2020 mexico 0\n",
      "2020 mexico 1\n",
      "2020 mexico 2\n",
      "2020 mexico 3\n",
      "2020 alemania 0\n",
      "2020 alemania 1\n",
      "2020 alemania 2\n",
      "2020 alemania 3\n",
      "2020 arabia 0\n",
      "2020 arabia 1\n",
      "2020 arabia 2\n",
      "2020 arabia 3\n",
      "2020 australia 0\n",
      "2020 australia 1\n",
      "2020 australia 2\n",
      "2020 australia 3\n",
      "2020 brasil 0\n",
      "2020 brasil 1\n",
      "2020 brasil 2\n",
      "2020 brasil 3\n",
      "2020 canada 0\n",
      "2020 canada 1\n",
      "2020 canada 2\n",
      "2020 canada 3\n",
      "2020 china 0\n",
      "2020 china 1\n",
      "2020 china 2\n",
      "2020 china 3\n",
      "2020 corea del sur 0\n",
      "2020 corea del sur 1\n",
      "2020 corea del sur 2\n",
      "2020 corea del sur 3\n",
      "2020 francia 0\n",
      "2020 francia 1\n",
      "2020 francia 2\n",
      "2020 francia 3\n",
      "2020 india 0\n",
      "2020 india 1\n",
      "2020 india 2\n",
      "2020 india 3\n",
      "2020 indonesia 0\n",
      "2020 indonesia 1\n",
      "2020 indonesia 2\n",
      "2020 indonesia 3\n",
      "2020 italia 0\n",
      "2020 italia 1\n",
      "2020 italia 2\n",
      "2020 italia 3\n",
      "2020 japon 0\n",
      "2020 japon 1\n",
      "2020 japon 2\n",
      "2020 japon 3\n",
      "2020 uk 0\n",
      "2020 uk 1\n",
      "2020 uk 2\n",
      "2020 uk 3\n",
      "2020 rusia 0\n",
      "2020 rusia 1\n",
      "2020 rusia 2\n",
      "2020 rusia 3\n",
      "2020 sudafrica 0\n",
      "2020 sudafrica 1\n",
      "2020 sudafrica 2\n",
      "2020 sudafrica 3\n",
      "2020 turquia 0\n",
      "2020 turquia 1\n",
      "2020 turquia 2\n",
      "2020 turquia 3\n",
      "2020 eu 0\n",
      "2020 eu 1\n",
      "2020 eu 2\n",
      "2020 eu 3\n",
      "2020 usa 0\n",
      "2020 usa 1\n",
      "2020 usa 2\n",
      "2020 usa 3\n",
      "2021 argentina 0\n",
      "2021 argentina 1\n",
      "2021 argentina 2\n",
      "2021 argentina 3\n",
      "2021 mexico 0\n",
      "2021 mexico 1\n",
      "2021 mexico 2\n",
      "2021 mexico 3\n",
      "2021 alemania 0\n",
      "2021 alemania 1\n",
      "2021 alemania 2\n",
      "2021 alemania 3\n",
      "2021 arabia 0\n",
      "2021 arabia 1\n",
      "2021 arabia 2\n",
      "2021 arabia 3\n",
      "2021 australia 0\n",
      "2021 australia 1\n",
      "2021 australia 2\n",
      "2021 australia 3\n",
      "2021 brasil 0\n",
      "2021 brasil 1\n",
      "2021 brasil 2\n",
      "2021 brasil 3\n",
      "2021 canada 0\n",
      "2021 canada 1\n",
      "2021 canada 2\n",
      "2021 canada 3\n",
      "2021 china 0\n",
      "2021 china 1\n",
      "2021 china 2\n",
      "2021 china 3\n",
      "2021 corea del sur 0\n",
      "2021 corea del sur 1\n",
      "2021 corea del sur 2\n",
      "2021 corea del sur 3\n",
      "2021 francia 0\n",
      "2021 francia 1\n",
      "2021 francia 2\n",
      "2021 francia 3\n",
      "2021 india 0\n",
      "2021 india 1\n",
      "2021 india 2\n",
      "2021 india 3\n",
      "2021 indonesia 0\n",
      "2021 indonesia 1\n",
      "2021 indonesia 2\n",
      "2021 indonesia 3\n",
      "2021 italia 0\n",
      "2021 italia 1\n",
      "2021 italia 2\n",
      "2021 italia 3\n",
      "2021 japon 0\n",
      "2021 japon 1\n",
      "2021 japon 2\n",
      "2021 japon 3\n",
      "2021 uk 0\n",
      "2021 uk 1\n",
      "2021 uk 2\n",
      "2021 uk 3\n",
      "2021 rusia 0\n",
      "2021 rusia 1\n",
      "2021 rusia 2\n",
      "2021 rusia 3\n",
      "2021 sudafrica 0\n",
      "2021 sudafrica 1\n",
      "2021 sudafrica 2\n",
      "2021 sudafrica 3\n",
      "2021 turquia 0\n",
      "2021 turquia 1\n",
      "2021 turquia 2\n",
      "2021 turquia 3\n",
      "2021 eu 0\n",
      "2021 eu 1\n",
      "2021 eu 2\n",
      "2021 eu 3\n",
      "2021 usa 0\n",
      "2021 usa 1\n",
      "2021 usa 2\n",
      "2021 usa 3\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"5a84958b-8499-4cf3-9dd8-acc2ec81108a\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"5a84958b-8499-4cf3-9dd8-acc2ec81108a\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get predictions for all files with tweets\n",
    "%load_ext jupyternotify\n",
    "\n",
    "path = 'predictions/Lexicon/'\n",
    "for year in years:\n",
    "    for lang in langs:\n",
    "        lexicon = openLexicon(lang)\n",
    "        countries = dic_countries[lang]\n",
    "        for country in countries:\n",
    "            for subject in range(0,4):\n",
    "                print(str(year) + ' ' + country + ' ' + str(subject))\n",
    "                name_file = country + ' ' + str(year) + ' - Tema ' + str(subject)\n",
    "                df_tweets = readFile(year, lang, name_file)\n",
    "                # Arabia 2020 no tiene tweets para ser transformados\n",
    "                #corregir codigo para cuando no se tengan tweets\n",
    "                if(len(df_tweets) > 0):\n",
    "                    #predicted_emotions = predict_emotions(df_tweets, lexicon)\n",
    "                    predicted_emotions = predictDaily(df_tweets, lexicon)\n",
    "                    dfNew = pd.DataFrame.from_dict(predicted_emotions, orient='index')\n",
    "                    dfNew = dfNew.reset_index()\n",
    "                    dfNew.columns = ['date', 'Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust', 'No emotion']\n",
    "                    dfNew.sort_values(by='date',ascending=True, inplace=True)\n",
    "                    pathfile = path + str(year) + \"/\" + lang + \"/\"\n",
    "                    dfNew.to_csv(pathfile + country + \" \" + str(year) + \" - Tema \" + str(subject) + \".csv\", encoding=\"utf-8\", sep=\"\\t\", index=False)\n",
    "%notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900169f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
