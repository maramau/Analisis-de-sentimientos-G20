{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planeo traducir los datasets en ingles a otros idiomas a traves de DeepL. Para ello, me hice una cuenta premium en la cual DeepL me permite traducir documentos de hasta 1M de caracteres (en realidad un poco menos, pero esto no lo anuncian).\n",
    "\n",
    "Como algunos de los datasets tienen mas de 1M de caracteres, el plan es partirlos en varios documentos de hasta cierto umbral (850k), mandarlos a traducir a DeepL, y luego unificarlos con los sentimientos de los datasets originales en el mismo orden.\n",
    "\n",
    "Ahora prosigo a desarmarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'datasetCrowdflower2M' #3 millones de caracteres. debe ser partido en 3\n",
    "file2 = 'datasetElectoral2M' #400k no hay necesidad de partirlo para Deepl\n",
    "file3 = 'datasetEmoInt2M' #400k no hay necesidad de partirlo\n",
    "file4 = 'datasetTEC2M'#1 millon 40k. Debe ser partido en 2\n",
    "fileUnificado = 'datasetUnificado'\n",
    "\n",
    "chosen_file = file4\n",
    "dic_partitions = {file1:3, file2:1, file3:1, file4:2}\n",
    "partitions = dic_partitions[chosen_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(chosen_file+'.csv', sep='\\t', encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thinks that @melbahughes had a great 50th birt...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Como una expresi贸n tan simple una sola oraci贸n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the moment when you get another follower and y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eww.. my moms starting to make her annual rum ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If ur heart hurts all the time for tht person ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0  Thinks that @melbahughes had a great 50th birt...        7\n",
       "1  Como una expresi贸n tan simple una sola oraci贸n...        3\n",
       "2  the moment when you get another follower and y...        1\n",
       "3  eww.. my moms starting to make her annual rum ...        4\n",
       "4  If ur heart hurts all the time for tht person ...        1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5103db13ecd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mlist_documents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_doc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_paragraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mact_chars\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "path='toTranslate/'\n",
    "\n",
    "list_documents = list()\n",
    "for i in range(partitions):\n",
    "    list_documents.append(Document())\n",
    "\n",
    "act_chars = 0\n",
    "umbral_chars = 850000\n",
    "index_doc = 0\n",
    "\n",
    "for i in range(len(df['text'])):\n",
    "    list_documents[index_doc].add_paragraph(df['text'][i])\n",
    "    act_chars+=len(df['text'][i])\n",
    "    \n",
    "    #Si la siguiente iteracion supera el umbral de deepl, guardo el archivo compeltoado y sigo imprimiendo en el proximo archivo\n",
    "    if act_chars + len(df['text'][i]) > umbral_chars or i==len(df['text'])-1:\n",
    "        list_documents[index_doc].save(path+chosen_file+'- a traducir - parte'+str(index_doc+1)+'.docx')\n",
    "        index_doc+=1\n",
    "        act_chars = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo los datasets 1 y 4 desarmados pero traducidos, prosigo a rearmarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import docx\n",
    "\n",
    "path_united_en = 'datasets/united/en/' #Dataset ya armado con etiquetas en ingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n",
      "Finalizada la parte 1\n",
      "Finalizada la parte 2\n",
      "Finalizada la parte 3\n",
      "Finalizada la parte 4\n",
      "Creando diccionario\n",
      "Creando DataFrame\n",
      "pt\n",
      "Finalizada la parte 1\n",
      "Finalizada la parte 2\n",
      "Finalizada la parte 3\n",
      "Finalizada la parte 4\n",
      "Creando diccionario\n",
      "Creando DataFrame\n"
     ]
    }
   ],
   "source": [
    "#Armo el dataset Crowdflower\n",
    "df_en1 = pd.read_csv(path_united_en+'datasetCrowdflower2-en.csv', encoding='utf-16', sep='\\t')\n",
    "\n",
    "\n",
    "for lang in ['es', 'pt']:\n",
    "    list_texts = list()\n",
    "    list_emotions = list()\n",
    "    idx_emotion = 0\n",
    "    print(lang)\n",
    "    path_parts = 'datasets/parts/'+lang+'/' #Dataset con las traducciones separadas en varios archivos sin etiquetas\n",
    "    path_united_translated = 'datasets/united/'+lang+'/' #Dataset donde iran las traducciones unidas con etiquetas\n",
    "    for i in range(1,5):\n",
    "        d1 = docx.Document(path_parts + 'datasetCrowdflower2M- a traducir - parte' + str(i) + ' '+lang+'.docx')\n",
    "        for j in range(len(d1.paragraphs)):\n",
    "            text = d1.paragraphs[j].text.replace('\\t', ' ') #Elimino la UNICA tabulacion que aparece en todo el dataset\n",
    "                                                            # leccion del dia: SIEMPRE hay que eliminar\n",
    "                                                            # el caracter que usas como separador\n",
    "              #Reemplazo los textos que considero que tienen errores\n",
    "            list_texts.append(d1.paragraphs[j].text)    #Por un string que interpretare como no valido\n",
    "            list_emotions.append(df_en1['emotion'][idx_emotion])\n",
    "            idx_emotion+=1\n",
    "        print('Finalizada la parte '+ str(i))\n",
    "    print('Creando diccionario')\n",
    "    dic_es = {'text':list_texts, 'emotion':list_emotions}\n",
    "    print('Creando DataFrame')\n",
    "    complete_df1 = pd.DataFrame(dic_es)\n",
    "    complete_df1.count()\n",
    "    complete_df1.to_csv(path_united_translated + 'datasetCrowdflower2-'+lang+'.csv', sep='\\t',\n",
    "                        encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearmo el dataset Electoral\n",
    "\n",
    "list_texts = list()\n",
    "list_emotions = list()\n",
    "\n",
    "df_en2 = pd.read_csv(path_united_en+'datasetElectoral2M.csv', encoding='utf-16', sep='\\t')\n",
    "\n",
    "d2 = docx.Document(path_parts + 'datasetElectoral2M- a traducir ' + lang +'.docx')\n",
    "\n",
    "for j in range(len(d2.paragraphs)):\n",
    "    list_texts.append(d2.paragraphs[j].text)\n",
    "    list_emotions.append(df_en2['emotion'][j])\n",
    "\n",
    "dic_es = {'text':list_texts, 'emotion':list_emotions}\n",
    "complete_df2 = pd.DataFrame(dic_es)\n",
    "complete_df2.to_csv(path_united_translated + 'datasetElectoral'+lang+'.csv', sep='\\t', encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearmo el dataset Emoint\n",
    "\n",
    "list_texts = list()\n",
    "list_emotions = list()\n",
    "\n",
    "df_en3 = pd.read_csv(path_united_en+'datasetEmoInt2-en.csv', encoding='utf-16', sep='\\t')\n",
    "\n",
    "d3 = docx.Document(path_parts + 'datasetEmoInt2M- a traducir '+lang+'.docx')\n",
    "\n",
    "for j in range(len(d3.paragraphs)):\n",
    "    list_texts.append(d3.paragraphs[j].text)\n",
    "    list_emotions.append(df_en3['emotion'][j])\n",
    "dic_es = {'text':list_texts, 'emotion':list_emotions}\n",
    "complete_df3 = pd.DataFrame(dic_es)\n",
    "complete_df3.to_csv(path_united_translated + 'datasetEmoInt'+lang+'.csv', sep='\\t', encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n",
      "Finalizada la parte 1\n",
      "Finalizada la parte 2\n",
      "Creando diccionario\n",
      "Creando DataFrame\n"
     ]
    }
   ],
   "source": [
    "#Rearmo el dataset Tec\n",
    "\n",
    "df_en4 = pd.read_csv(path_united_en+'datasetTec2-en.csv', encoding='utf-16', sep='\\t')\n",
    "\n",
    "for lang in ['es']:\n",
    "    list_texts = list()\n",
    "    list_emotions = list()\n",
    "    idx_emotion = 0\n",
    "    print(lang)\n",
    "    path_parts = 'datasets/parts/'+lang+'/' #Dataset con las traducciones separadas en varios archivos sin etiquetas\n",
    "    path_united_translated = 'datasets/united/'+lang+'/' #Dataset donde iran las traducciones unidas con etiquetas\n",
    "    for i in range(1,3):\n",
    "        d4 = docx.Document(path_parts + 'datasetTEC2M- a traducir - parte' + str(i) + ' '+lang+'.docx')\n",
    "        for j in range(len(d4.paragraphs)):\n",
    "            text = d4.paragraphs[j].text.replace('\\t', ' ') #Elimino la UNICA tabulacion que aparece en todo el dataset\n",
    "                                                            # leccion del dia: SIEMPRE hay que eliminar\n",
    "                                                            # el caracter que usas como separador\n",
    "              #Reemplazo los textos que considero que tienen errores\n",
    "            list_texts.append(d4.paragraphs[j].text)    #Por un string que interpretare como no valido\n",
    "            list_emotions.append(df_en4['emotion'][idx_emotion])\n",
    "            idx_emotion+=1\n",
    "        print('Finalizada la parte '+ str(i))\n",
    "    print('Creando diccionario')\n",
    "    dic_es = {'text':list_texts, 'emotion':list_emotions}\n",
    "    print('Creando DataFrame')\n",
    "    complete_df4 = pd.DataFrame(dic_es)\n",
    "    complete_df4.to_csv(path_united_translated + 'datasetTec'+lang+'.csv', sep='\\t', encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datasets son muy peque帽os. El dataset unificado deberia ser de 64147 entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'pt'\n",
    "\n",
    "pathTrans = 'datasets/united/'+lang+'/'\n",
    "fileTrans1 = pathTrans + 'datasetCrowdflower2-'+lang+'.csv'\n",
    "fileTrans2 = pathTrans + 'datasetElectoral2-'+lang+'.csv'\n",
    "fileTrans3 = pathTrans + 'datasetEmoInt2-'+lang+'.csv'\n",
    "fileTrans4 = pathTrans + 'datasetTec2-'+lang+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(fileTrans1, encoding='utf-16', sep='\\t')\n",
    "df2 = pd.read_csv(fileTrans2, encoding='utf-16', sep='\\t')\n",
    "df3 = pd.read_csv(fileTrans3, encoding='utf-16', sep='\\t')\n",
    "df4 = pd.read_csv(fileTrans4, encoding='utf-16', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text       39727\n",
      "emotion    39739\n",
      "dtype: int64\n",
      "text       4055\n",
      "emotion    4055\n",
      "dtype: int64\n",
      "text       7097\n",
      "emotion    7101\n",
      "dtype: int64\n",
      "text       13249\n",
      "emotion    13252\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1.count())\n",
    "print(df2.count())\n",
    "print(df3.count())\n",
    "print(df4.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUnificado = df1.append(df2).append(df3).append(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text       64133\n",
      "emotion    64147\n",
      "dtype: int64\n",
      "64147\n"
     ]
    }
   ],
   "source": [
    "print(dfUnificado.count())\n",
    "print(len(dfUnificado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39739"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1) #Deberia ser de 39739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4055"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2) #Deberia ser de 4055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7101"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df3) #Deberia ser de 7101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13252"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df4) #Este deberia ser de 13252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUnificado.to_csv(pathTrans + 'datasetUnificado2'+lang+'.csv', sep='\\t', encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39739\n",
      "4055\n",
      "7101\n",
      "13252\n"
     ]
    }
   ],
   "source": [
    "print(len(df1))\n",
    "print(len(df2))\n",
    "print(len(df3))\n",
    "print(len(df4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64142</th>\n",
       "      <td>About to have a movie night with my booboo @je...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64143</th>\n",
       "      <td>@TheBodyShopUK Knowing my dissertation will be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64144</th>\n",
       "      <td>hospital tomorrow morning strapped with wires ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64145</th>\n",
       "      <td>Work is soooo slow ready to have a great saturday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64146</th>\n",
       "      <td>You realize that by choosing joy every single ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  emotion\n",
       "64142  About to have a movie night with my booboo @je...        3\n",
       "64143  @TheBodyShopUK Knowing my dissertation will be...        1\n",
       "64144  hospital tomorrow morning strapped with wires ...        1\n",
       "64145  Work is soooo slow ready to have a great saturday        1\n",
       "64146  You realize that by choosing joy every single ...        1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathEn = 'datasets/united/en/'\n",
    "fileEn = pathEn + 'datasetUnificado2-en.csv'\n",
    "\n",
    "dfEn = pd.read_csv(fileEn, encoding='utf-16', sep='\\t')\n",
    "\n",
    "dfEn.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13247</th>\n",
       "      <td>Prestes a ter uma noite de cinema com meu boob...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13248</th>\n",
       "      <td>@TheBodyShopUK Sabendo que minha disserta莽茫o s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13249</th>\n",
       "      <td>hospital amanh茫 de manh茫 amarrado com arames e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13250</th>\n",
       "      <td>O trabalho 茅 muito lento, pronto para ter um 贸...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13251</th>\n",
       "      <td>Voc锚 percebe que ao escolher a alegria em cada...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  emotion\n",
       "13247  Prestes a ter uma noite de cinema com meu boob...        3\n",
       "13248  @TheBodyShopUK Sabendo que minha disserta莽茫o s...        1\n",
       "13249  hospital amanh茫 de manh茫 amarrado com arames e...        1\n",
       "13250  O trabalho 茅 muito lento, pronto para ter um 贸...        1\n",
       "13251  Voc锚 percebe que ao escolher a alegria em cada...        1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUnificado.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
