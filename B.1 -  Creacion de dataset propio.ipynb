{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceso el dataset unificado de la universidad de Stuttgart y lo edito para mis fines.\n",
    "\n",
    "Entre lo que hago esta:\n",
    "1. Cambiar el formato de utf-8 a utf-16. ocupo el doble de espacio pero podre ver los emojis y otros caracteres especiales (13/06/2021: creo que esto al final nunca lo termine usando)\n",
    "2. Procesar los escapes html que aparecen en los datasets crowdflower y emoint, como & quot ; y & amp ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"C:\\\\Users\\\\maram\\\\Proyecto-final\\\\modulos\\\\unify-emotion-datasets\\\\unified-dataset.jsonl\",\"r\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170687"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'VAD': {'valence': None, 'arousal': None, 'dominance': None},\n",
       " 'source': 'affectivetext',\n",
       " 'text': 'Mortar assault leaves at least 18 dead',\n",
       " 'emotions': {'joy': 0.0,\n",
       "  'anger': 0.22,\n",
       "  'sadness': 0.64,\n",
       "  'disgust': 0.02,\n",
       "  'fear': 0.6,\n",
       "  'trust': None,\n",
       "  'surprise': 0.0,\n",
       "  'love': None,\n",
       "  'noemo': None,\n",
       "  'confusion': None,\n",
       "  'anticipation': None,\n",
       "  'shame': None,\n",
       "  'guilt': None},\n",
       " 'split': 'trial',\n",
       " 'emotion_model': 'Ekman',\n",
       " 'domain': 'headlines',\n",
       " 'labeled': 'multi'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "list_dics = list()\n",
    "\n",
    "for line in text:\n",
    "    list_dics.append(json.loads(line))\n",
    "\n",
    "list_dics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I think @Sam_Canaday &amp; @KYLEJDOWSON must actually have to be working like me &amp; @dowson_brady because I havent got any snap chat videos today'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dics[148031].get('text',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think @Sam_Canaday and @KYLEJDOWSON must actually have to be working like me and @dowson_brady because I havent got any snap chat videos today\n"
     ]
    }
   ],
   "source": [
    "#Pruebo como hacer el escape de codigo html\n",
    "from html import unescape\n",
    "\n",
    "str = unescape(list_dics[148031].get('text',None));\n",
    "str = str.replace('&', 'and')\n",
    "\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'affectivetext',\n",
       " 'crowdflower',\n",
       " 'dailydialog',\n",
       " 'electoraltweets',\n",
       " 'emoint',\n",
       " 'emotion-cause',\n",
       " 'fb-valence-arousal-anon',\n",
       " 'grounded_emotions',\n",
       " 'isear'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veo que modelos hay en el dataset\n",
    "list_models = list()\n",
    "\n",
    "for d in list_dics:\n",
    "    list_models.append(d.get(\"source\",None))\n",
    "\n",
    "set_models = set(list_models)\n",
    "\n",
    "set_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4056"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hago una lista con los datos del dataset de mi eleccion\n",
    "dataset = list()\n",
    "\n",
    "for d in list_dics:\n",
    "    if d.get(\"source\") == 'electoraltweets':\n",
    "        dataset.append(d)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defino una funcion que toma una lista de diccionarios y toma los\n",
    "    #datos relevantes a un csv\n",
    "#Escribir el csv de esta forma tiene el inconveniente de imprimir \\n fila de por medio\n",
    "import csv\n",
    "from html import unescape\n",
    "\n",
    "path = 'datasets/en/'\n",
    "\n",
    "def write_csv(dataset):\n",
    "    file_new = open(path+'datasetElectoral2.csv','w', encoding='utf-16')\n",
    "    writer = csv.writer(file_new, delimiter='\\t')\n",
    "    writer.writerow(['text',\n",
    "                   'joy',\n",
    "                   'anger',\n",
    "                   'sadness',\n",
    "                   'disgust',\n",
    "                   'fear',\n",
    "                   'trust',\n",
    "                   'surprise',\n",
    "                   'anticipation'\n",
    "                    ])\n",
    "    for dic in dataset:\n",
    "        writer.writerow([\n",
    "                    unescape(dic['text']),#Agrego el encode porque algunos textos tenian comillas simples que Python no interpretaba bien\n",
    "                    dic['emotions']['joy'],\n",
    "                    dic['emotions']['anger'],\n",
    "                    dic['emotions']['sadness'],\n",
    "                    dic['emotions']['disgust'],\n",
    "                    dic['emotions']['fear'],\n",
    "                    dic['emotions']['trust'],\n",
    "                    dic['emotions']['surprise'],\n",
    "                    dic['emotions']['anticipation']\n",
    "                    ]\n",
    "                   )\n",
    "    file_new.close()\n",
    "\n",
    "write_csv(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapto el dataset para utilizar Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes me permite clasificar texto en varias categorías, aunque necesito sí o sí tener UNA SOLA variable Y.\n",
    "Por eso adapto el csv del dataset.\n",
    "\n",
    "Lo que hice fue alterar los datasets para que, en lugar de tener 1's y 0's según la aparición o no aparición de cada sentimiento, haya un solo campo 'emotion' que vaya del 0 al 8 indicando cual es el sentimiento que aparece. Siendo:\n",
    "\n",
    "0. SIN EMOCION\n",
    "1. JOY\n",
    "2. ANGER\n",
    "3. SADNESS\n",
    "4. DISGUST\n",
    "5. FEAR\n",
    "6. TRUST\n",
    "7. SURPRISE\n",
    "8. ANTICIPATION\n",
    "\n",
    "Esto no es una limitación en los datasets Electoral-Tweets y CrowdFlower, ya que estos solo tienen valores binarios para los sentimientos y solo indican la aparición de un solo sentimiento por texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_emotions_P = ['No emo','Joy','Anger','Sadness','Disgust','Fear','Trust','Surprise','Anticipation']\n",
    "list_emotions_E = ['No emo','Joy','Anger','Sadness','Disgust','Fear','Surprise']\n",
    "dic_emotions_P = {'no emo':0, 'joy':1, 'anger':2, 'sadness':3, 'disgust':4, 'fear':5, 'trust':6, 'surprise':7, 'anticipation':8}\n",
    "dic_emotions_E = {'No emo':0, 'Joy':1, 'Anger':2, 'Sadness':3, 'Disgust':4, 'Fear':5, 'Surprise':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "path = 'datasets//en/'\n",
    "df = pd.read_csv(path+'datasetElectoral2.csv', encoding='utf-16', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>trust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>anticipation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm a #Republican, but if I have to hear my mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will Obama fire the person responsible for thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haha @DickMorrisTweet Romney is going to have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S/0 to my newest @freeboosieRS &amp; vote for Obam...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nicki Minaj Fucked Up With That Mitt Romney Li...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  joy  anger  sadness  \\\n",
       "0  I'm a #Republican, but if I have to hear my mo...    0      0        0   \n",
       "1  Will Obama fire the person responsible for thi...    0      1        0   \n",
       "2  haha @DickMorrisTweet Romney is going to have ...    0      1        0   \n",
       "3  S/0 to my newest @freeboosieRS & vote for Obam...    0      0        0   \n",
       "4  Nicki Minaj Fucked Up With That Mitt Romney Li...    0      1        0   \n",
       "\n",
       "   disgust  fear  trust  surprise  anticipation  \n",
       "0        1     0      0         0             0  \n",
       "1        0     0      0         0             0  \n",
       "2        0     0      0         0             0  \n",
       "3        0     0      0         0             1  \n",
       "4        0     0      0         0             0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 349, 569, 31, 1637, 91, 808, 251, 318]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construyo el csv del nuevo dataset\n",
    "file_new = open(path+'datasetElectoral2M.csv','w', encoding='utf-16')\n",
    "writer = csv.writer(file_new, delimiter='\\t')\n",
    "writer.writerow(['text','emotion'])\n",
    "\n",
    "#Arreglo para calcular la cantidad de apariciones de cada sentimiento en el dataset\n",
    "emotions_array = [0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "for i in range(1,len(df)):\n",
    "    row = df.loc[i]\n",
    "    text = row[\"text\"]\n",
    "    #Busco la emocion caracteristica (se asume que solo se expresa una emocion)\n",
    "    emotion = 0 #SIN EMOCION\n",
    "    for j in range(1,9):\n",
    "        if row[j] == 1:\n",
    "            emotion = j\n",
    "    emotions_array[emotion]+=1\n",
    "    \n",
    "    #Reemplazo caracteres invalidos por ? para adaptar el texto a utf-8\n",
    "    #text = text.replace(u\"\\uFFFD\", \"?\")\n",
    "    writer.writerow([text,emotion])\n",
    "\n",
    "file_new.close()\n",
    "emotions_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de sentimientos de CrowdFlower es Ekman. Por esto los sentimientos TRUST y ANTICIPATION no tienen apariciones.\n",
    "\n",
    "Algo interesante a señalar es la aparición de los sentimientos según el dataset. Los sentimientos más comunes en Electoral-Tweets son DISGUST y JOY, mientras que en CrowdFlower son NO_EMO, JOY y FEAR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edito el dataset TEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(path+'datasetTEC.txt','r',encoding='utf-8')\n",
    "\n",
    "text = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['145353048817012736\\tThinks that @melbahughes had a great 50th birthday party :)\\tsurprise', '144279638024257536\\tComo una expresión tan simple una sola oración puede llegara dañarte tanto.\\tsadness', '140499585285111809\\tthe moment when you get another follower and you cheer.\\tjoy']\n"
     ]
    }
   ],
   "source": [
    "list_texts = list()\n",
    "\n",
    "for t in text:\n",
    "    new_text = t.replace(\" \\t:: \", \"\\t\")\n",
    "    new_text = new_text.replace(\":\\t\", \"\\t\")\n",
    "    new_text = new_text.replace(\"\\n\", \"\")\n",
    "    new_text = new_text.replace(\",\", \"\")\n",
    "    list_texts.append(unescape(new_text))\n",
    "\n",
    "print(list_texts[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_new = open(path+'datasetTEC2.csv','w',encoding='utf-16')\n",
    "writer = csv.writer(file_new, delimiter='\\t')\n",
    "writer.writerow(['ID','text','emotion'])\n",
    "for line in list_texts:\n",
    "    if line != '':\n",
    "        l = line.split('\\t')\n",
    "        writer.writerow([l[0],l[1],l[2]])\n",
    "\n",
    "file_new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_new = open(path+'datasetTEC2.csv','r',encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = file_new.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(path+'datasetUnificado.csv','r', encoding='utf-16', delimiter='\\t')\n",
    "\n",
    "type(df.emotion[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thinks that @melbahughes had a great 50th birthday party :),7\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_new = open(path+'datasetTEC2M.csv','r',encoding='utf-16')\n",
    "text = file_new.readlines()\n",
    "text[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construyendo el dataset unificado de los 4 subsets construidos anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abierto: datasets/united/es/datasetCrowdflower2-es.csv\n",
      "Abierto: datasets/united/es/datasetElectoral2-es.csv\n",
      "Abierto: datasets/united/es/datasetEmoInt2-es.csv\n",
      "Abierto: datasets/united/es/datasetTec2-es.csv\n"
     ]
    }
   ],
   "source": [
    "#Uno los datasets mejorados (.*M.csv) en uno solo\n",
    "import pandas as pd\n",
    "path = 'datasets/united/'+lang+'/'\n",
    "path_file1 = path+'datasetCrowdflower2-'+lang+'.csv'\n",
    "path_file2 = path+'datasetElectoral2-'+lang+'.csv'\n",
    "path_file3 = path+'datasetEmoInt2-'+lang+'.csv'\n",
    "path_file4 = path+'datasetTec2-'+lang+'.csv'\n",
    "\n",
    "df1 = pd.read_csv(path_file1, sep='\\t', encoding='utf-16') #Ekman, un solo sentimiento por tweet\n",
    "df2 = pd.read_csv(path_file2, sep='\\t', encoding='utf-16') #Plutchick, un solo sentimiento por tweet\n",
    "df3 = pd.read_csv(path_file3, sep='\\t', encoding='utf-16') #Ekman, un solo sentimiento por tweet\n",
    "df4 = pd.read_csv(path_file4, sep='\\t', encoding='utf-16') #Ekman, un solo sentimiento por tweet\n",
    "\n",
    "print('Abierto: '+path_file1)\n",
    "print('Abierto: '+path_file2)\n",
    "print('Abierto: '+path_file3)\n",
    "print('Abierto: '+path_file4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "name_file_new = path+'datasetUnificado-'+lang+'.csv'\n",
    "\n",
    "#Construyo el csv del nuevo dataset unificado\n",
    "writer_file_new = open(name_file_new,'w',encoding='utf-8')\n",
    "writer = csv.writer(writer_file_new, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creado: datasets/united/es/datasetUnificado-es.csv\n"
     ]
    }
   ],
   "source": [
    "#Escribo el contenido del nuevo dataset unificado\n",
    "writer.writerow(['text','emotion'])\n",
    "\n",
    "i = 2\n",
    "for i in range(len(df1)):\n",
    "    if df1.text[i] != '\\n':\n",
    "        writer.writerow([df1.text[i],df1.emotion[i]])\n",
    "\n",
    "i = 2\n",
    "for i in range(len(df2)):\n",
    "    if df2.text[i] != '\\n':\n",
    "        writer.writerow([df2.text[i],df2.emotion[i]])\n",
    "        \n",
    "i = 2\n",
    "for i in range(len(df3)):\n",
    "    if df3.text[i] != '\\n':\n",
    "        writer.writerow([df3.text[i],df3.emotion[i]])\n",
    "        \n",
    "i = 2\n",
    "for i in range(len(df4)):\n",
    "    if df4.text[i] != '\\n':\n",
    "        writer.writerow([df4.text[i],df4.emotion[i]])\n",
    "        \n",
    "file_new.close()\n",
    "print('Creado: '+name_file_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
